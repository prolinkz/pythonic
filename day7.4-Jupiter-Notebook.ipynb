{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is Python Notebook. Where we can write code and document it at one place.\n",
    "# Write Code, Markdown. Run Cell Code invidually or All at once. Ctrl+Alt+Enter\n",
    "# Execute above cell, below cell, Split cell\n",
    "# View and manage Variables window\n",
    "# Select  Kernel > (ml_env) enviroment. Before selecting Kernal make sure you have installed the Kernal library, like\n",
    "(ml_env) C:/user/docs/project -folder> pip install ipykernal\n",
    "# Once ipykernel install, then select Kernel, and Select Python Environment > (ml_env) environment > Now Run Code.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importing necessary libraries and load Titanic online dataset\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "sb.load_dataset(\"titanic\")\n",
    "\n",
    "# or we can keep the dataset data into variable. First we will create variable\n",
    "boat =sb.load_dataset(\"titanic\")    # boat now is panda DataFrame\n",
    "boat    # In notebook we don't need to write print() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Load Online dataset from a source file using Pandas library, and store data into Excel file\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "kashti = sb.load_dataset(\"titanic\")     # this kashti variable is now a panda dataframe\n",
    "\n",
    "#  we can convert to oter formats like to_html, to_dict, to_json, to_csv\n",
    "\n",
    "# Save the DataFrame to an excel file\n",
    "kashti.to_excel(kashti)     # convert to Excel file. \n",
    "\n",
    "### if it giive a Module_Error for missing openpyxl module, then we should need to install the openpyxl library, like;\n",
    ">    pip install openpyxl  # we can now run and install library in notebook any of the above cell.\n",
    "\n",
    "# or we can simply save it with .xlsx format extension to Save the DataFrame to an excel file\n",
    "kashti.to_excel('Kashti.xlsx', index=False)\n",
    "\n",
    "# Save to a folder\n",
    "kashti.to_excel('/Users/Desktop/dataset/dataframe.xlsx')\n",
    "kashti.to_excel(\"../dataset/dataframe.xlsx\") #\n",
    "kashti.to_excel(\"../dataset/dataframe.csv\") # comma separated values format file. cover low space\n",
    "\n",
    "# Save to downward directory\n",
    "kashti.to_excel('C:/Users/HPO2PCHI/Downloads/dataframe.xlsx')\n",
    "\n",
    "\n",
    "## To READ the Imported datset files\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data_sets/kashti.csv\") # this function will import the dataframe and load to read\n",
    "df  # load csv file \n",
    "# or we can use the below command\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "# Loading the dataset\n",
    "boston = datasets.load_boston() # It contains all features of boston houses along with their prices in $1000\n",
    "print(boston)\n",
    "# Converting to DataFrame for easy manipulation\n",
    "df=pd.DataFrame(data=boston['data'],columns=boston[\"feature_names\"])\n",
    "df['Price'] = boston['target']  ## Adding Price column from target variable which has price values in thousands\n",
    "print(df.head())\n",
    "# Adding target variable price into dataframe df\n",
    "df[\"Price\"]=boston[\"target\"]\n",
    "print(df.head())\n",
    "# Splitting data set into training and testing sets 85%-15% respectively\n",
    "train_x=df[[\"RM\",\"LSTAT\"]]   # Features used for prediction\n",
    "test_x=df[[\"RM\",\"LSTAT\"]][490:]    # Testing on remaining rows\n",
    "train_y=df[\"Price\"][0:490]     # Target values corresponding to train_x\n",
    "test_y=df[\"Price\"][490:]      # Corresponding test targets\n",
    "regr = linear_model.LinearRegression()       # Creating Linear Regression object regr\n",
    "regr.fit (train_x, train_y)                 # Training model using fit method\n",
    "# Predicting house prices for test data\n",
    "predicted_prices=regr.predict(test_x)\n",
    "# Calculating R^2 value for our predictions\n",
    "r2_value=(r2_score(test_y, predicted_prices)) * 100\n",
    "print(\"The coefficient of determination: %s\" % r2_value)\n",
    "plt.scatter(test_y, predicted_prices )        # Plotting actual vs predicted prices\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas Tips and Tricks\n",
    "\n",
    "# pandas tips\n",
    "import numpy as np  # useful for many scientific computing in Python\n",
    "import pandas as pd  # the data manipulation library used by DataFrame\n",
    "from scipy import stats  # for statistical analysis\n",
    "# Create a dataframe from an existing CSV file.\n",
    "df = pd.read_csv('data/gapminder_gdp_asia.csv', index_col='country')\n",
    "print(df)\n",
    "\n",
    "## To know all the file information in rows, columns, entries (index)\n",
    "df.info()\n",
    "\n",
    "\n",
    "# Top Head\n",
    "df.head(10)     # print top 10 rows\n",
    "\n",
    "# Bottom rows\n",
    "df.tail(5)   # print last 5 rows from dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Indexing, Selection & Filtering\n",
    "# ### Select column or row of specific value: `loc` vs `iloc`.\n",
    "# loc is label based indexing. It can be any type of object that we can use to identify rows or columns.\n",
    "# iloc is integer position based indexing. It only accepts positive integers.\n",
    "\n",
    "# example: select all rows where GDP > 1000\n",
    "print(\"Select all rows where gdpPercap_2007 > 1000\")\n",
    "print(df[df['gdpPercap_2007']>1000])\n",
    "\n",
    "# example: select first two rows with gdpPercap_2007 > 500\n",
    "print(\"\\nSelect first two rows with gdpPercap_2007 > 500:\")\n",
    "print(df[:3][df[\"gdpPercap_2007\"] > 500].head())\n",
    "\n",
    "# example: select last two rows with gdpPercap_2007 < 400\n",
    "print(\"\\nSelect last two rows with gdpPercap_2007 < 400:\")\n",
    "print(df[-2:][df[\"gdpPercap_2007\"] < 400].tail())\n",
    "\n",
    "# example: select every other country between Australia and Canada (inclusive).\n",
    "print(\"\\nSelect every other country between Australia and Canada (inclusive):\")\n",
    "print(df[(df[\"country\"].isin([\"Austria\", \"Canada\"])) |\n",
    "         ((df[\"country\"].isin([\"Australia\"]) == False) &\n",
    "          (df[\"country\"].isin([\"Canada\"]) == False))]].sample(frac=0.5))\n",
    "\n",
    "# ### Use `.at[]`, `.iat[]` instead of `[ ]` when you want to access single element within your Dataframe.\n",
    "# The difference is that these functions return scalar values while [ ] returns series.\n",
    "# python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read \"10 minutes to Pandas\" web page on Pandas website"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
