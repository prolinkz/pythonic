{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Book    https://wesmckinney.com/book/python-builtin#set\n",
    "# - Cheatsheet https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "# - DataSet     https://www.kaggle.com/account/login?titleType=dataset-downloads&showDatasetDownloadSkip=False&messageId=datasetsWelcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is pandas? \n",
    "Pandas is a powerful data manipulation library in Python. It provides high-level data structures and data analysis tools for the Python programming language. \n",
    "A high-level data manipulation tool built on the Numpy package.\n",
    "Designed to make data cleaning and analysis quick and easy in Python.\n",
    "\n",
    "Core components: \n",
    "Series: One-dimensional labeled arrays.\n",
    "DataFrame: Two-dimensional labeled data structures, much like a table in a database, an Excel spreadsheet, or a data frame in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open Conda and check the available environments\n",
    "\n",
    "# (base) C:/users> conda env list\n",
    "\n",
    "## To remove conda environments:\n",
    "# >conda remove -n enironment_name  # or try\n",
    "# >conda env remove -n env_name\n",
    "\n",
    "## To create new environment\n",
    "#conda create --name myenv python=3.7   # create myenv environment with Python version 3.7\n",
    "# conda create -n python_eda python     # create environement and python\n",
    "\n",
    "## Activate an existing environment\n",
    "#conda activate myenv\n",
    "\n",
    "## Deactivate current active environment\n",
    "#conda deactivate\n",
    "\n",
    "## To List all conda environments\n",
    "# conda env list\n",
    "\n",
    "## To list \n",
    "#conda info --envs\n",
    "\n",
    "\n",
    "## Install packages in specific environment\n",
    "#conda install -n myenv numpy pandas matplotlib seaborn scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (base) > conda env list\n",
    "# (base) > conda create -n python_eda python3.11\n",
    "\n",
    "## once environemt created, enter into environment\n",
    "# (base) > conda activate python_eda\n",
    "# (pthon_eda) > conda list    # it will show all installed fiiles\n",
    "\n",
    "## To install kernel\n",
    "# (pthon_eda) > pip install ipkernel\n",
    "\n",
    "## To install Pandas library\n",
    "# (pthon_eda) > pip install pandas\n",
    "\n",
    "## To install openxl library\n",
    "# (pthon_eda) > pip install pyopenxl\n",
    "\n",
    "\n",
    "\n",
    "#### OPEN new file with Python Notebook extension ipynb, like pandas.ipynb\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "## Read the data\n",
    "#df = pd.read_csv('./data/dataset.csv')\n",
    "\n",
    "## Write the data. we will need to install the pyopenxl library\n",
    "# df.to_excel('datafile.xlsx')\n",
    "\n",
    "## To Read Excel File\n",
    "# df_xl = pd.read_excel('datafile.xlsx')\n",
    "\n",
    "## print the variable or dataset in Terminal \n",
    "# print(df)\n",
    "\n",
    "## How data looks like\n",
    "# df.info()\n",
    "\n",
    "## To print data types\n",
    "#df.dtypes \n",
    "\n",
    "## Print top 5 rows\n",
    "# df.head(10)\n",
    "\n",
    "## print Last 5 rows\n",
    "# df.tail(5)\n",
    "\n",
    "## To describe all the data in short summary\n",
    "# df.describe()\n",
    "\n",
    "## Check for missing values\n",
    "# df.isnull().sum()\n",
    "\n",
    "## Drop NA / Null value rows\n",
    "# df=df.dropna()\n",
    "\n",
    "## check if there is any duplicate row\n",
    "# df.duplicated().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Tips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment \n",
    "- Ensure you have Python and pip installed in separate coda environment\n",
    "- Install pandas with pip install pandas\n",
    "- Use Jupyter Notebooks or any Python environment to interactively work with pandas.\n",
    "\n",
    "## Dive into Basic Operations\n",
    "- Loading Data: Understand how to read data from various sources like CSV, Excel, SQL databases.\n",
    "<code> import pandas as pd\n",
    "data = pd.read_csv('datafile.csv')\n",
    "</code>\n",
    "\n",
    "- Viewing Data: \n",
    "Use commands like <code> head(), tail(), info() </code> and <code> describe() </code> to get an overview of your dataset.\n",
    "\n",
    "- Indexing & Selecting Data: \n",
    "Get to grips with <code> .loc[], .iloc[], </code> and conditional selection.\n",
    "\n",
    "- Exploring Data: Know about basic functions such as <code>.head()</code>, <code>.info()</code> for getting\n",
    "a quick look at your dataset.\n",
    "- Filtering Data: Learn about filtering using boolean indexing.\n",
    "- Sorting & Ordering: Get familiar with sorting and ordering operations on a dataframe.\n",
    "\n",
    "- Cleaning Data: Learn how to clean missing values using dropna(), fillna() etc.,\n",
    "renaming columns, selecting specific rows/columns.\n",
    "\n",
    "- Selecting Data: Learn about different ways of selecting specific rows/columns using labels, indices, slicing etc.\n",
    "\n",
    "- Selecting Columns: How do we select a particular column? We can use square brackets [] after our dataframe object to access columns by name.\n",
    "- Selecting Rows & Columns : How do we select rows/columns of a DataFrame? We can use loc[] for label based indexing (select by \n",
    "\n",
    "\n",
    "- Selecting Rows & Columns : How do we select rows/columns of a DataFrame?\n",
    "<code> df = pd.DataFrame({'A':[1,2,3], 'B':[4,5,6]})\n",
    "print(df)\n",
    "#Select column B\n",
    "print(\"Column B:\")\n",
    "print(df['B'])\n",
    "#Select row where A is greater than 2\n",
    "print(\"\\nRow Where A > 2\")\n",
    "print(df[df['A'] > 2])\n",
    "</code>\n",
    "\n",
    "\n",
    "- Selecting Data: Learn about selecting specific rows/columns using loc[] function.\n",
    "<code> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df.loc[0, ['A', 'B']] # Returns a series of columns A and B for row index 0\n",
    "df.loc[[0, 1]] # Returns all rows at indices 0 and 1\n",
    "</code>\n",
    "\n",
    "\n",
    "- Selecting Data: Learn about selecting specific rows/columns using indexing and slicing techniques.\n",
    "<code>df[0] #first row of dataframe\n",
    "df[:3] # first three rows of a dataframe\n",
    "df['columnname'] #select column by name\n",
    "df[['col1','col2']] # select multiple columns at once\n",
    "</code>\n",
    "\n",
    "- Filtering Data: Explore different ways of filtering data based on conditions such as greater than, less than, equal to etc.\n",
    "\n",
    "- Filtering Rows & Columns: Filter out unwanted values based on conditions that we specify for each element (row) / value pair(column).\n",
    "\n",
    "- Filtering Data: Explore different ways to filter data based on conditions.\n",
    "<code>#filter out all records where columm 'A' is greater than value x\n",
    "df[(df['A'] > x)]\n",
    "</code>\n",
    "\n",
    "- Sorting Data: Get familiar with sorting methods for both ascending and descending order.\n",
    "<code> df.sort_values(by='ColumnName',ascending=True)</code>\n",
    "- Group By: Understand the concept of grouping in pandas and use it to perform various operations like mean, sum, max or min.\n",
    "- Group By: Understand the concept of grouping in pandas.\n",
    "<code>grouped = df.groupby('ColumnName')\n",
    "for key, group in grouped:\n",
    "print (key)\n",
    "print (group)</code>\n",
    "\n",
    "- Group By & Aggregate: Perform group by operations and aggregate functions such as mean(), sum(), max().\n",
    "<code>df.groupby(['Column Name']).mean()</code>\n",
    "\n",
    "## sort values in decreasing order\n",
    "<code> df.sort_index() </code>\n",
    "\n",
    "\n",
    "## Advanced Topics\n",
    "\n",
    "### Missing Values\n",
    "Handling missing values can be tricky but it‚Äôs an important part of working with real world datasets. Let‚Äôs explore some basic strategies.\n",
    "Handling missing values can be crucial when working with real world datasets. Pandas provides several options to handle them.\n",
    "Handling missing values can be tricky but it‚Äôs an important part of working with datasets. Here are some basic steps to handle them:\n",
    "- How do we handle missing values?\n",
    "- What are common strategies to deal with them?\n",
    "\n",
    "#### Dealing With Nulls (NaN's):\n",
    "- Check if there are NaN's present in your dataset.\n",
    "<code>df.isnull().sum()</code>\n",
    "- Drop Rows containing null values - dropna():\n",
    "<code>df.dropna()</code>\n",
    "- Fill NaN's with some meaningful value fillna():\n",
    "<code>df.fillna({'Age':5})</code>\n",
    "- Forward filling NaN's:\n",
    "<code>df.ffill()</code>\n",
    "- Backward filling NaN's:\n",
    "<code>df.bfill()</code>\n",
    "- Interpolation method to fill NaN's:\n",
    "<code>df.interpolate()</code>\n",
    "\n",
    "### Duplicate Entries\n",
    "- Find duplicate entries within the same DataFrame.\n",
    "<code>duplicates = df[df.duplicated(keep=False)]</code>\n",
    "- Remove duplicates:\n",
    "<code>df.drop_duplicates(inplace=True)</code>\n",
    "\n",
    "### Merging, Joining, Concatenating\n",
    "- Different types of joins available: inner join, outer join, left join, right join, full join.\n",
    "- Example code:\n",
    "<code>merged_dataframe = pd.merge(left=df1,right=df2,on=\"common_column\")</code>\n",
    "- Concat function can be used to combine two or more dataframes along any axis.\n",
    "<code>pd.concat([df1,df2],axis=0)</code>\n",
    "\n",
    "\n",
    "\n",
    "### Data Cleaning üßπ\n",
    "- Handling Missing Data: Utilize methods like dropna(), fillna(), and understand the importance of inplace parameter.\n",
    "\n",
    "- Data Type Conversion: Grasp astype() to convert data types and understand pandas‚Äô native data types.\n",
    "\n",
    "- Removing Duplicates: Employ drop_duplicates() to maintain data integrity.\n",
    "\n",
    "### Data Manipulation & Analysis üìà\n",
    "- Aggregation: Use powerful grouping and aggregation tools like groupby(), pivot_table(), and crosstab().\n",
    "\n",
    "- String Operations: Dive into the .str accessor for essential string operations within Series.\n",
    "\n",
    "- Merging, Joining, and Concatenating: Understand the differences and applications of merge(), join(), and concat().\n",
    "- Date Time Operations: Understand how to work with datetime objects using to_datetime() and date_range().\n",
    "- Missing Values Handling: Learn about handling missing values such as dropping rows/columns with NaN's, forward filling,\n",
    "\n",
    "- Reshaping Data: Grasp melt() and pivot() for transforming datasets.\n",
    "\n",
    "## 3. Pandas Visualization üêºüêº\n",
    "- Basic plotting functions: use hist(), boxplot(), scatter(), etc., on a dataframe.\n",
    "- Advanced visualizations: bar plots, line charts, heatmaps, correlation matrices, etc.\n",
    "- Customizing Plots: customize colors, labels, sizes, titles, etc.\n",
    "## 4. Python Libraries Used In Data Science üíª\n",
    "- Numpy\n",
    "- Matplotlib\n",
    "- Seaborn\n",
    "\n",
    "## Advanced Features üé©\n",
    "- Time Series in pandas: Work with date-time data, resampling, and shifting.\n",
    "\n",
    "- Categorical Data: Understand pandas‚Äô categorical type and its advantages.\n",
    "\n",
    "- Styling: Style your DataFrame output for better visualization in Jupyter Notebooks.\n",
    "Handling Missing Values: Fill missing values with mean/median/mode/etc.\n",
    "\n",
    "- Data Wrangling: Perform complex transformations such as multiple column conversions, merges, and splits.\n",
    "\n",
    "Practice Problems üèãÔ∏è‚Äç‚ôÄÔ∏è\n",
    "Apply these concepts to solve real world problems related to data analysis and manipulation.\n",
    "\n",
    "## Optimization & Scaling üöÄ\n",
    "- Efficiently using Data Types: Use category type for object columns with few unique values to save memory.\n",
    "\n",
    "- Method Chaining: Reduce the readability problem of pandas and improve performance.\n",
    "\n",
    "- Use eval() & query(): High-performance operations, leveraging string expressions.\n",
    "\n",
    "## Pandas‚Äô Ecosystem üåç\n",
    "- Other Libraries: Explore libraries like Dask for parallel computing and Vaex for handling large datasets.\n",
    "\n",
    "- Visualization: While pandas itself has visualization capabilities, integrating it with Matplotlib and Seaborn can enhance your data visualization game.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
